//
//  ScanViewModel.swift
//  SUPERWAAGE
//
//  Enhanced scan view model with professional-grade accuracy
//  Apple Senior Developer implementation with all advanced components
//

import SwiftUI
import ARKit
import RealityKit
import Combine

// MARK: - Helper Extensions
extension Float {
    static let degreesToRadian = Float.pi / 180
}

enum ScanState: Equatable {
    case idle
    case scanning
    case processing
    case completed
    case error(String)
}

/// Lightweight mesh data structure (doesn't retain ARFrames)
struct ExtractedMeshData {
    let identifier: UUID
    let vertexCount: Int
    let faceCount: Int
    let timestamp: Date

    init(from anchor: ARMeshAnchor) {
        self.identifier = anchor.identifier
        self.vertexCount = anchor.geometry.vertices.count
        self.faceCount = anchor.geometry.faces.count
        self.timestamp = Date()
    }
}

@MainActor
class ScanViewModel: NSObject, ObservableObject {
    // MARK: - Published Properties
    @Published var scanState: ScanState = .idle
    @Published var volume_cm3: Double = 0.0
    @Published var weight_g: Double = 0.0
    @Published var dimensions: SIMD3<Float> = .zero
    @Published var scanProgress: Double = 0.0
    @Published var qualityScore: Double = 0.0

    // ‚úÖ NEW: Live volume estimation during scan
    @Published var liveVolumeEstimate: Double = 0.0
    @Published var volumeStability: Double = 0.0
    @Published var volumeTrend: VolumeTrend = .unknown
    @Published var scanRecommendation: String = "üîÑ Bereit zum Scannen"

    // ‚úÖ AI/ML Integration
    @Published var aiCoordinator = AICoordinator()
    @Published var aiEnabled: Bool = true
    @Published var aiStatistics: AIStatistics?
    @Published var confidence: Double = 0.0
    @Published var errorMessage: String?
    @Published var meshAnchors: [ARMeshAnchor] = []
    @Published var recommendations: [String] = []
    @Published var selectedMaterial: MaterialPreset
    @Published var isMultiScanMode: Bool = false

    // Scan metrics for UI
    @Published var pointCount: Int = 0
    @Published var averageConfidence: Float = 0.0
    @Published var coverageScore: Float = 0.0
    @Published var scanDuration: TimeInterval = 0.0

    // Segmentation metrics (for background removal)
    @Published var segmentationCoverage: Float = 0.0

    // Accuracy and quality metrics
    @Published var accuracyPercentage: Double = 0.0
    @Published var accuracyDescription: String = ""
    @Published var accuracyColor: String = ""
    @Published var symmetryScore: Float = 0.0
    @Published var errorMarginPercent: Double = 0.0  // ¬±X% error margin
    @Published var errorMarginDescription: String = ""

    // MARK: - Private Properties
    private var arSession: ARSession?
    private var lastCamera: ARCamera?  // ‚úÖ FIX: Store camera to avoid ARFrame retention
    private var scannedPoints: [simd_float3] = []
    private var scannedNormals: [simd_float3] = []

    // AI refinement toggle (disabled by default for reliability)
    private let enableAIRefinement = false  // Disabled to prevent processing hangs

    // ‚úÖ CRASH FIX: Disable TSDF to prevent marching cubes crashes
    private let enableTSDFReconstruction = false  // Use simple mesh-based calculation instead
    private var scannedConfidence: [Float] = []
    private var cancellables = Set<AnyCancellable>()
    private var scanStartTime: Date?
    private var detectedPlaneHeight: Float?

    // SLAM tracking quality
    @Published var trackingQuality: TrackingQuality = .limited

    // MARK: - Computed Properties

    /// Volume in milliliters (same as cm¬≥)
    var volumeML: Float {
        return Float(volume_cm3)
    }

    // MARK: - Tunable Parameters (AI/LiDAR Optimizations)

    /// Quality preset selection
    @Published var scanQuality: ScanQuality = .balanced

    // Camera movement thresholds (from DepthViz best practices)
    private var cameraRotationThreshold: Float { cos(scanQuality.rotationDegrees * .degreesToRadian) }
    private var cameraTranslationThreshold: Float { pow(scanQuality.translationMeters, 2) }
    private var lastCameraTransform: simd_float4x4?
    private var currentCameraTransform: simd_float4x4?

    // Point limiting (from DepthViz) - prevents memory issues
    private var maxPoints: Int { scanQuality.maxPoints }
    private var currentPointIndex = 0

    // Confidence filtering threshold (0=low, 1=medium, 2=high)
    private var confidenceThreshold: Float { scanQuality.minConfidence }

    // MARK: - Scan Metrics & Statistics

    @Published var totalPointsScanned: Int = 0
    @Published var totalFramesProcessed: Int = 0
    @Published var totalFramesSkipped: Int = 0
    @Published var currentFPS: Double = 0.0
    @Published var estimatedMemoryUsage: Double = 0.0 // in MB

    private var lastFrameTime: Date?
    private var frameTimeHistory: [TimeInterval] = []
    private let maxFrameHistory = 30 // For FPS smoothing

    // MARK: - Scan Quality Presets

    enum ScanQuality: String, CaseIterable {
        case performance = "Performance"
        case balanced = "Balanced"
        case quality = "Quality"
        case maximum = "Maximum"

        var rotationDegrees: Float {
            switch self {
            case .performance: return 3.0  // More lenient - skip more frames
            case .balanced: return 1.0     // DepthViz default
            case .quality: return 0.5      // More sensitive
            case .maximum: return 0.25     // Very sensitive
            }
        }

        var translationMeters: Float {
            switch self {
            case .performance: return 0.03  // 3cm
            case .balanced: return 0.01     // 1cm - DepthViz default
            case .quality: return 0.005     // 5mm
            case .maximum: return 0.0025    // 2.5mm
            }
        }

        var maxPoints: Int {
            switch self {
            case .performance: return 250_000
            case .balanced: return 500_000
            case .quality: return 1_000_000
            case .maximum: return 2_000_000
            }
        }

        var minConfidence: Float {
            switch self {
            case .performance: return 0.3  // Low threshold
            case .balanced: return 0.5     // Medium
            case .quality: return 0.6      // Higher
            case .maximum: return 0.7      // High only
            }
        }

        var description: String {
            switch self {
            case .performance: return "Schnell, niedrige Dichte"
            case .balanced: return "Ausgewogen (empfohlen)"
            case .quality: return "Hohe Qualit√§t, mehr Punkte"
            case .maximum: return "Maximale Details, langsam"
            }
        }
    }

    enum TrackingQuality {
        case limited
        case normal
        case good

        var description: String {
            switch self {
            case .limited: return "Eingeschr√§nkt"
            case .normal: return "Normal"
            case .good: return "Gut"
            }
        }

        var color: Color {
            switch self {
            case .limited: return .red
            case .normal: return .orange
            case .good: return .green
            }
        }
    }

    // Advanced Components
    private let multiScanManager = MultiScanManager()
    private let calibrationManager = CalibrationManager.shared
    private let accuracyEvaluator = AccuracyEvaluator()
    private let volumeEstimator = VolumeEstimator()
    private let spatialAnalyzer = SpatialDensityAnalyzer()

    // ‚úÖ NEW: Live volume estimation
    private let liveVolumeEstimator = LiveVolumeEstimator()

    // Object Selection Components (Tap-to-Select)
    private let objectSelector = ObjectSelector()
    private let boundingBoxVisualizer = BoundingBoxVisualizer()
    @Published var selectedObject: SelectedObject?
    @Published var isObjectSelected: Bool = false

    // 3D Model Components
    @Published var meshVolumeResult: MeshVolumeResult?
    @Published var can3DExport: Bool = false
    @Published var meshQualityDescription: String = ""

    // MARK: - Initialization
    override init() {
        // Default material
        self.selectedMaterial = DensityDatabase.defaultPreset
        super.init()
        setupBindings()
        setupAI()
    }

    // MARK: - Setup
    private func setupBindings() {
        // Auto-calculate weight when volume or material changes
        Publishers.CombineLatest($volume_cm3, $selectedMaterial)
            .sink { [weak self] volume, material in
                self?.calculateWeight()
            }
            .store(in: &cancellables)

        // Multi-scan progress
        multiScanManager.$scanProgress
            .sink { [weak self] progress in
                self?.scanProgress = progress
            }
            .store(in: &cancellables)

        multiScanManager.$scanQualityScore
            .sink { [weak self] quality in
                self?.qualityScore = quality
            }
            .store(in: &cancellables)
    }

    // ‚úÖ AI SETUP
    private func setupAI() {
        guard aiEnabled else { return }

        // Setup auto-detection callback (#1: YOLO)
        aiCoordinator.onAutoDetection = { [weak self] detected in
            guard let self = self else { return }
            print("ü§ñ AI: Auto-detected \(detected.identifier) - triggering selection")

            // Auto-select detected object
            if let position = detected.worldPosition {
                Task { @MainActor in
                    // Simulate tap at detected position
                    self.handleAIAutoSelection(at: position)
                }
            }
        }

        // Setup material detection callback (#4: Material Classification)
        aiCoordinator.onMaterialDetected = { [weak self] material in
            guard let self = self else { return }
            print("ü§ñ AI: Auto-detected material - \(material.name)")

            Task { @MainActor in
                self.selectedMaterial = material
                self.recommendations = [
                    "‚ú® AI: Material automatisch erkannt",
                    "üìä Dichte: \(material.density) g/cm¬≥",
                    "üéØ Genauigkeit: 85-95%"
                ]
            }
        }

        print("ü§ñ AI System initialized with all 6 features")
    }

    // ‚úÖ AI: Handle auto-selection from YOLO detection
    private func handleAIAutoSelection(at position: SIMD3<Float>) {
        // This will be called when YOLO detects an object
        print("ü§ñ AI Auto-Selection at position: \(position)")

        // Find closest mesh anchor to detected position
        var closestAnchor: ARMeshAnchor?
        var minDistance: Float = .infinity

        for anchor in meshAnchors {
            let anchorPos = SIMD3<Float>(
                anchor.transform.columns.3.x,
                anchor.transform.columns.3.y,
                anchor.transform.columns.3.z
            )
            let distance = simd_distance(position, anchorPos)

            if distance < minDistance {
                minDistance = distance
                closestAnchor = anchor
            }
        }

        if closestAnchor != nil, minDistance < 0.5 {  // Within 50cm
            print("   ‚úÖ Found nearby mesh anchor - auto-selecting")
            isObjectSelected = true
            recommendations = [
                "ü§ñ Objekt automatisch erkannt!",
                "‚úÖ KI-basierte Auswahl",
                "üìç Bereit zum Scannen"
            ]
        }
    }

    func setARSession(_ session: ARSession) {
        self.arSession = session
    }

    /// Update current camera transform for movement detection
    /// Called from ARSessionDelegate to avoid ARFrame retention
    func updateCameraTransform(_ transform: simd_float4x4) {
        self.currentCameraTransform = transform
    }

    // MARK: - Material Selection
    func setMaterial(_ material: MaterialPreset) {
        self.selectedMaterial = material

        // Configure multi-scan based on material type
        if material.category == .flour || material.category == .powder {
            multiScanManager.setupForMaterialType(.powder)
            isMultiScanMode = true
        } else if material.category == .spices {
            multiScanManager.setupForMaterialType(.irregular)
            isMultiScanMode = true
        } else if material.category == .dairy {
            multiScanManager.setupForMaterialType(.solid)
            isMultiScanMode = false
        } else {
            multiScanManager.setupForMaterialType(.granular)
            isMultiScanMode = selectedMaterial.densityRange != nil
        }
    }

    // MARK: - Calibration
    func performCalibration(knownObject: CalibrationManager.KnownObject, scannedPoints: [simd_float3]) -> CalibrationResult {
        return calibrationManager.calibrate(with: knownObject, scannedPoints: scannedPoints)
    }

    var isCalibrated: Bool {
        return calibrationManager.isCalibrated
    }

    var calibrationStatus: String {
        return calibrationManager.statusDescription
    }

    var calibrationAccuracyColor: String {
        return calibrationManager.accuracyColor
    }

    // MARK: - Object Selection (Tap-to-Select)

    /// Handle tap gesture for object selection
    /// - Parameters:
    ///   - screenPoint: Tap location in screen coordinates
    ///   - arView: ARView for raycast
    func handleObjectSelection(at screenPoint: CGPoint, in arView: ARView) {
        print("üéØ Object selection at: \(screenPoint)")

        // ‚úÖ STEP 1: Try improved RANSAC-based selection first (best accuracy)
        if !meshAnchors.isEmpty {
            if let selected = objectSelector.selectObjectImproved(
                at: screenPoint,
                in: arView,
                meshAnchors: meshAnchors
            ) {
                self.selectedObject = selected
                self.isObjectSelected = true

                print("   ‚úÖ Object selected (RANSAC): \(selected.points.count) points, confidence: \(Int(selected.confidence * 100))%")

                // ‚úÖ User feedback
                self.recommendations = [
                    "‚úÖ Objekt erfolgreich ausgew√§hlt!",
                    "üìä \(selected.points.count) Punkte erfasst",
                    "üéØ Genauigkeit: \(Int(selected.confidence * 100))%"
                ]

                // ‚úÖ Use Oriented Bounding Box for better fit
                if let obb = selected.orientedBoundingBox {
                    print("   üì¶ Using OBB (tighter fit): \(obb.volume * 1_000_000) cm¬≥")

                    // Convert OBB to AABB for visualization compatibility
                    let aabbBox = obb.toAxisAligned()
                    let measurements = BoundingBoxMeasurements(boundingBox: aabbBox)

                    boundingBoxVisualizer.showBoundingBox(
                        aabbBox,
                        in: arView,
                        withMeasurements: measurements
                    )

                    // Use OBB volume (more accurate)
                    self.volume_cm3 = Double(obb.volume * 1_000_000)
                    self.dimensions = obb.size * 100.0
                } else {
                    // Fallback to regular bounding box
                    let measurements = BoundingBoxMeasurements(boundingBox: selected.boundingBox)
                    boundingBoxVisualizer.showBoundingBox(
                        selected.boundingBox,
                        in: arView,
                        withMeasurements: measurements
                    )
                    self.volume_cm3 = Double(measurements.volume_cm3)
                    self.dimensions = selected.boundingBox.size * 100.0
                }
                return
            }
        }

        // ‚úÖ STEP 2: Fallback to original mesh-based selection
        print("   ‚ÑπÔ∏è RANSAC selection unavailable - trying original mesh selection...")
        if !meshAnchors.isEmpty {
            if let selected = objectSelector.selectObject(
                at: screenPoint,
                in: arView,
                meshAnchors: meshAnchors
            ) {
                self.selectedObject = selected
                self.isObjectSelected = true

                print("   ‚úÖ Object selected (original mesh): \(selected.points.count) points")

                let measurements = BoundingBoxMeasurements(boundingBox: selected.boundingBox)
                boundingBoxVisualizer.showBoundingBox(
                    selected.boundingBox,
                    in: arView,
                    withMeasurements: measurements
                )

                self.volume_cm3 = Double(measurements.volume_cm3)
                self.dimensions = selected.boundingBox.size * 100.0
                return
            }
        }

        // ‚úÖ STEP 3: Last resort - depth-based selection
        print("   ‚ÑπÔ∏è Mesh selection failed - trying depth-based selection...")
        if let selected = selectObjectFromDepth(at: screenPoint, in: arView) {
            self.selectedObject = selected
            self.isObjectSelected = true

            print("   ‚úÖ Object selected (depth): \(selected.points.count) points")

            let measurements = BoundingBoxMeasurements(boundingBox: selected.boundingBox)
            boundingBoxVisualizer.showBoundingBox(
                selected.boundingBox,
                in: arView,
                withMeasurements: measurements
            )

            self.volume_cm3 = Double(measurements.volume_cm3)
            self.dimensions = selected.boundingBox.size * 100.0
        } else {
            print("   ‚ùå Object selection failed (all methods)")

            // ‚úÖ User feedback for failed selection
            self.recommendations = [
                "‚ùå Objekt konnte nicht ausgew√§hlt werden",
                "üí° Tipp: Tippe direkt auf das Objekt",
                "üìç Stelle sicher, dass das Objekt vollst√§ndig gescannt wurde",
                "üîç Bewege dich n√§her heran (20-50cm Abstand)"
            ]
        }
    }

    /// Clear object selection
    func clearObjectSelection(in arView: ARView) {
        selectedObject = nil
        isObjectSelected = false
        boundingBoxVisualizer.removeBoundingBox(from: arView)
    }

    /// ‚úÖ IMPROVED: Select object from depth point cloud with direct depth fallback
    private func selectObjectFromDepth(at screenPoint: CGPoint, in arView: ARView) -> SelectedObject? {
        // Method 1: Try estimated plane raycast
        let results = arView.raycast(
            from: screenPoint,
            allowing: .estimatedPlane,
            alignment: .any
        )

        if let firstResult = results.first {
            let hitPoint = SIMD3<Float>(
                firstResult.worldTransform.columns.3.x,
                firstResult.worldTransform.columns.3.y,
                firstResult.worldTransform.columns.3.z
            )
            print("   ‚úì Raycast hit (estimated plane): \(hitPoint)")
            return selectPointsNearLocation(hitPoint)
        }

        // Method 2: Try existing plane geometry
        let planeResults = arView.raycast(
            from: screenPoint,
            allowing: .existingPlaneGeometry,
            alignment: .any
        )

        if let fallbackResult = planeResults.first {
            let hitPoint = SIMD3<Float>(
                fallbackResult.worldTransform.columns.3.x,
                fallbackResult.worldTransform.columns.3.y,
                fallbackResult.worldTransform.columns.3.z
            )
            print("   ‚úì Raycast hit (existing plane): \(hitPoint)")
            return selectPointsNearLocation(hitPoint)
        }

        // Method 3: Use depth buffer to find closest point to screen tap
        print("   ‚ÑπÔ∏è No plane found - using depth buffer direct selection")
        return selectNearestPointFromDepth(at: screenPoint, in: arView)
    }

    /// ‚úÖ NEW: Find nearest scanned point to screen tap using depth data
    private func selectNearestPointFromDepth(at screenPoint: CGPoint, in arView: ARView) -> SelectedObject? {
        guard !scannedPoints.isEmpty else {
            print("   ‚ùå No scanned points available")
            return nil
        }

        guard let currentFrame = arView.session.currentFrame else {
            print("   ‚ùå No current AR frame")
            return nil
        }

        // Convert screen point to camera coordinates
        let viewportSize = arView.bounds.size
        let normalizedPoint = CGPoint(
            x: screenPoint.x / viewportSize.width,
            y: screenPoint.y / viewportSize.height
        )

        // Create a ray from camera through the screen point
        let camera = currentFrame.camera
        let cameraTransform = camera.transform
        let cameraPosition = SIMD3<Float>(
            cameraTransform.columns.3.x,
            cameraTransform.columns.3.y,
            cameraTransform.columns.3.z
        )

        // Unproject screen point to world space ray
        // For a point at normalized screen coordinates, create a ray direction
        _ = Float(normalizedPoint.x * 2 - 1) // -1 to 1 (screenX, unused in favor of pixelX)
        _ = Float((1 - normalizedPoint.y) * 2 - 1) // -1 to 1, flipped Y (screenY, unused in favor of pixelY)

        let intrinsics = camera.intrinsics
        let fx = intrinsics[0, 0]
        let fy = intrinsics[1, 1]
        let cx = intrinsics[0, 2]  // ‚úÖ FIXED: was [2,0] - incorrect indexing
        let cy = intrinsics[1, 2]  // ‚úÖ FIXED: was [2,1] - incorrect indexing

        // Create direction in camera space
        let pixelX = Float(screenPoint.x)
        let pixelY = Float(screenPoint.y)
        let directionCamera = SIMD3<Float>(
            (pixelX - cx) / fx,
            (pixelY - cy) / fy,
            -1.0
        )

        // Transform to world space
        let rotationMatrix = simd_float3x3(
            cameraTransform.columns.0.xyz,
            cameraTransform.columns.1.xyz,
            cameraTransform.columns.2.xyz
        )
        let directionWorld = normalize(rotationMatrix * directionCamera)

        // Find closest point along the ray
        var closestPoint: SIMD3<Float>?
        var minDistance: Float = .infinity

        for point in scannedPoints {
            // Vector from camera to point
            let toPoint = point - cameraPosition

            // Project point onto ray
            let projectionLength = dot(toPoint, directionWorld)

            // Only consider points in front of camera
            guard projectionLength > 0 else { continue }

            // Point on ray closest to scanned point
            let pointOnRay = cameraPosition + directionWorld * projectionLength

            // Distance from scanned point to ray
            let distanceToRay = length(point - pointOnRay)

            // Find point with minimum distance to ray (within 0.5m threshold)
            if distanceToRay < 0.5 && projectionLength < minDistance {
                closestPoint = point
                minDistance = projectionLength
            }
        }

        guard let hitPoint = closestPoint else {
            print("   ‚ùå No points found near ray")
            return nil
        }

        print("   ‚úì Depth direct selection: \(hitPoint) (distance: \(String(format: "%.2f", minDistance))m)")
        return selectPointsNearLocation(hitPoint)
    }

    /// ‚úÖ IMPROVED: Find points near a 3D location with adaptive radius and smart object detection
    private func selectPointsNearLocation(_ location: SIMD3<Float>) -> SelectedObject? {
        guard !scannedPoints.isEmpty else {
            print("   ‚ùå No scanned points available")
            return nil
        }

        // ‚úÖ ADAPTIVE STRATEGY: Start small, grow if needed, but pick the BEST match
        // Small objects (cans, bottles): 5-10cm
        // Medium objects (books, bowls): 10-20cm
        // Large objects (boxes): 20-40cm
        let searchRadii: [Float] = [0.05, 0.08, 0.12, 0.15, 0.20, 0.30, 0.40]

        var bestCandidate: (points: [SIMD3<Float>], normals: [SIMD3<Float>], bbox: BoundingBox, radius: Float)?
        var bestScore: Float = -1

        for radius in searchRadii {
            var nearbyPoints: [SIMD3<Float>] = []
            var nearbyNormals: [SIMD3<Float>] = []

            // Find all points within radius
            for i in 0..<scannedPoints.count {
                let point = scannedPoints[i]
                let distance = simd_distance(point, location)

                if distance <= radius {
                    nearbyPoints.append(point)
                    if i < scannedNormals.count {
                        nearbyNormals.append(scannedNormals[i])
                    }
                }
            }

            // Need at least 50 points for a valid object (lowered from 100 for small items)
            guard nearbyPoints.count >= 50 else { continue }

            // Calculate bounding box
            guard let bbox = BoundingBox.from(points: nearbyPoints) else { continue }

            // ‚úÖ SMART SCORING: Prefer compact, dense objects over sprawling selections
            let volume = bbox.size.x * bbox.size.y * bbox.size.z
            let pointDensity = Float(nearbyPoints.count) / max(volume * 1_000_000, 0.0001) // points per cm¬≥

            // Aspect ratio check (avoid flat selections that grabbed the table)
            let dimensions = [bbox.size.x, bbox.size.y, bbox.size.z].sorted()
            let aspectRatio = dimensions[2] / max(dimensions[0], 0.001) // tallest / shortest

            // Compactness: how well points fill the bounding box (reserved for future scoring)
            _ = Float(nearbyPoints.count) / max(Float(nearbyPoints.count), 1.0)

            // Score formula: favor small, dense, 3D objects
            // Penalize: flat objects (table), low density (background), large radius (too much area)
            let densityScore = min(pointDensity / 100.0, 1.0) // normalize density
            let aspectScore = aspectRatio < 5.0 ? 1.0 : (5.0 / aspectRatio) // penalize flat objects
            let radiusScore = (0.4 - radius) / 0.4 // prefer smaller radius

            let score = densityScore * 0.4 + aspectScore * 0.4 + radiusScore * 0.2

            print("   üìä Radius \(Int(radius * 100))cm: \(nearbyPoints.count) pts, density: \(String(format: "%.1f", pointDensity)), aspect: \(String(format: "%.1f", aspectRatio)), score: \(String(format: "%.2f", score))")

            // Keep best candidate
            if score > bestScore {
                bestScore = score
                bestCandidate = (nearbyPoints, nearbyNormals, bbox, radius)
            }

            // Early exit if we found a really good compact object
            if score > 0.8 && nearbyPoints.count > 100 {
                print("   ‚úÖ High-quality match found early, stopping search")
                break
            }
        }

        // Return best candidate
        guard let candidate = bestCandidate else {
            print("   ‚ùå No valid object found in any radius")
            return nil
        }

        print("   üéØ BEST SELECTION: \(candidate.points.count) points at \(Int(candidate.radius * 100))cm radius (score: \(String(format: "%.2f", bestScore)))")

        // Calculate center
        let center = candidate.points.reduce(SIMD3<Float>.zero, +) / Float(candidate.points.count)

        // Calculate confidence based on best score
        let confidence = min(bestScore, 1.0)

        // For depth-based selection, we don't have a mesh anchor
        return SelectedObject(
            meshAnchor: nil,  // No mesh anchor for depth-based selection
            points: candidate.points,
            normals: candidate.normals,
            boundingBox: candidate.bbox,
            center: center,
            confidence: confidence
        )
    }

    // MARK: - Scanning Control
    func startScanning() {
        scanState = .scanning
        scannedPoints.removeAll()
        scannedNormals.removeAll()
        scannedConfidence.removeAll()
        meshAnchors.removeAll()
        volume_cm3 = 0.0
        weight_g = 0.0
        errorMessage = nil
        scanProgress = 0.0
        qualityScore = 0.0
        confidence = 0.0
        recommendations = []
        pointCount = 0
        coverageScore = 0.0
        scanStartTime = Date()

        // ‚úÖ NEW: Reset live volume estimator
        liveVolumeEstimator.reset()
        liveVolumeEstimate = 0.0
        volumeStability = 0.0
        volumeTrend = .unknown
        scanRecommendation = "üîÑ Bereit zum Scannen"

        // ‚úÖ AI: Start auto-detection
        if aiEnabled {
            aiCoordinator.startAutoDetection()
        }

        if isMultiScanMode {
            multiScanManager.startMultiScan()
        }
    }

    func completeScan() {
        print("üîÑ completeScan() called - Current state: \(scanState)")
        print("   Points: \(scannedPoints.count), Normals: \(scannedNormals.count)")

        // ‚úÖ AI: Stop auto-detection
        if aiEnabled {
            aiCoordinator.stopAutoDetection()
        }

        if isMultiScanMode && multiScanManager.currentScanIndex < multiScanManager.totalScans {
            // Record this scan
            print("   Multi-scan mode: Recording current scan")
            recordCurrentScan()
        } else {
            // ‚úÖ FIX: Store camera before releasing session to avoid ARFrame retention
            lastCamera = arSession?.currentFrame?.camera

            // ‚úÖ CRITICAL FIX: Copy mesh anchors NOW before they're cleared
            // This extracts all geometry data so we don't retain ARFrames
            let meshAnchorsCopy = meshAnchors.map { $0 }
            let meshCount = meshAnchors.count
            print("   üì¶ Captured \(meshCount) mesh anchors for processing")

            // Finalize scanning
            print("   Setting state to .processing")
            scanState = .processing
            scanDuration = Date().timeIntervalSince(scanStartTime ?? Date())

            // ‚úÖ FIX: Clear arSession reference to release all ARFrame references immediately
            print("   üßπ Releasing ARSession to free ARFrame references...")
            arSession = nil

            // ‚úÖ CRITICAL FIX: Clear mesh anchors immediately to avoid retaining ARFrames
            print("   üßπ Clearing mesh anchor references...")
            meshAnchors.removeAll()

            print("   Starting async processing task...")
            // Process mesh data in background to avoid freezing UI
            Task { [meshAnchorsCopy] in
                print("   üì± Task started - calling processMeshDataAsync() with \(meshAnchorsCopy.count) anchors")
                await self.processMeshDataAsync(withMeshAnchors: meshAnchorsCopy)
                print("   ‚úÖ Task completed")
            }
            print("   Task created, returning from completeScan()")
        }
    }

    private func recordCurrentScan() {
        // ‚úÖ FIX: Don't access currentFrame during scanning (causes ARFrame retention)
        // Use identity transform as fallback
        let cameraTransform = matrix_identity_float4x4
        // TODO: Pass camera transform from ARSession delegate to avoid frame retention

        multiScanManager.recordScan(
            points: scannedPoints,
            normals: scannedNormals,
            confidence: scannedConfidence,
            cameraTransform: cameraTransform
        )

        // Check if we need more scans
        if multiScanManager.currentScanIndex < multiScanManager.totalScans {
            // Prepare for next scan
            recommendations = [multiScanManager.getNextScanGuidance()]
            scannedPoints.removeAll()
            scannedNormals.removeAll()
            scannedConfidence.removeAll()
        } else {
            // All scans complete
            scanState = .processing

            // ‚úÖ CRITICAL FIX: Copy mesh anchors before clearing
            let meshAnchorsCopy = meshAnchors.map { $0 }
            meshAnchors.removeAll()  // Clear immediately to avoid ARFrame retention

            // Process mesh data in background
            Task { [meshAnchorsCopy] in
                await self.processMeshDataAsync(withMeshAnchors: meshAnchorsCopy)
            }
        }
    }

    func reset() {
        scanState = .idle
        scannedPoints.removeAll()
        scannedNormals.removeAll()
        scannedConfidence.removeAll()
        meshAnchors.removeAll()
        volume_cm3 = 0.0
        weight_g = 0.0
        dimensions = .zero
        scanProgress = 0.0
        qualityScore = 0.0
        confidence = 0.0
        recommendations = []
        errorMessage = nil
        multiScanManager.reset()
        detectedPlaneHeight = nil

        // Reset metrics
        totalPointsScanned = 0
        totalFramesProcessed = 0
        totalFramesSkipped = 0
        currentFPS = 0.0
        estimatedMemoryUsage = 0.0
        lastFrameTime = nil
        frameTimeHistory.removeAll()
        lastCameraTransform = nil
        currentCameraTransform = nil
        currentPointIndex = 0
    }

    // MARK: - Export & Sharing

    /// Export scan data as PLY file
    /// - Returns: URL of exported PLY file or nil if failed
    func exportPLY() -> URL? {
        guard !scannedPoints.isEmpty else {
            print("‚ùå No points to export")
            return nil
        }

        // Downsample for reasonable file size
        let downsampled = PointCloudUtils.voxelDownsample(
            points: scannedPoints,
            voxelSize: 0.005
        )

        let documentsURL = FileManager.default.urls(
            for: .documentDirectory,
            in: .userDomainMask
        )[0]

        let timestamp = Date().timeIntervalSince1970
        let filename = "scan_\(String(format: "%.0f", timestamp)).ply"
        let plyURL = documentsURL.appendingPathComponent(filename)

        do {
            if !scannedNormals.isEmpty && scannedNormals.count == scannedPoints.count {
                // Export with normals
                let downsampledNormals = PointCloudUtils.voxelDownsample(
                    points: scannedNormals,
                    voxelSize: 0.005
                )
                try PointCloudUtils.writePLYWithNormals(
                    points: downsampled,
                    normals: downsampledNormals,
                    url: plyURL
                )
            } else {
                // Export points only
                try PointCloudUtils.writePLY(points: downsampled, url: plyURL)
            }

            print("‚úÖ PLY exported: \(plyURL.path)")
            print("   Points: \(scannedPoints.count) ‚Üí \(downsampled.count) (downsampled)")
            return plyURL

        } catch {
            print("‚ùå PLY export failed: \(error)")
            return nil
        }
    }

    /// Export scan results as JSON summary
    /// - Returns: URL of exported JSON file or nil if failed
    func exportResultsJSON() -> URL? {
        let documentsURL = FileManager.default.urls(
            for: .documentDirectory,
            in: .userDomainMask
        )[0]

        let timestamp = Date().timeIntervalSince1970
        let filename = "results_\(String(format: "%.0f", timestamp)).json"
        let jsonURL = documentsURL.appendingPathComponent(filename)

        let results: [String: Any] = [
            "timestamp": timestamp,
            "volume_ml": volume_cm3,
            "weight_g": weight_g,
            "dimensions_cm": [
                "width": dimensions.x,
                "height": dimensions.y,
                "depth": dimensions.z
            ],
            "material": selectedMaterial.name,
            "material_density": selectedMaterial.density,
            "confidence": confidence,
            "quality_score": qualityScore,
            "coverage_score": coverageScore,
            "point_count": pointCount,
            "scan_duration_s": scanDuration,
            "accuracy_percentage": accuracyPercentage,
            "accuracy_description": accuracyDescription,
            "segmentation_coverage": segmentationCoverage
        ]

        do {
            let jsonData = try JSONSerialization.data(withJSONObject: results, options: .prettyPrinted)
            try jsonData.write(to: jsonURL)
            print("‚úÖ Results JSON exported: \(jsonURL.path)")
            return jsonURL

        } catch {
            print("‚ùå JSON export failed: \(error)")
            return nil
        }
    }

    /// Get shareable items for UIActivityViewController
    /// - Returns: Array of items to share
    func getShareableItems() -> [Any] {
        var items: [Any] = []

        // Add results text
        let resultsText = """
        SUPERWAAGE Scan Results

        Volume: \(formattedVolume)
        Weight: \(formattedWeight)
        Dimensions: \(formattedDimensions)
        Material: \(selectedMaterial.name)

        Quality: \(String(format: "%.0f", qualityScore * 100))%
        Confidence: \(String(format: "%.0f", confidence * 100))%
        Accuracy: \(accuracyDescription)
        """
        items.append(resultsText)

        // Add PLY file if available
        if let plyURL = exportPLY() {
            items.append(plyURL)
        }

        // Add JSON results if available
        if let jsonURL = exportResultsJSON() {
            items.append(jsonURL)
        }

        return items
    }

    // MARK: - Mesh Processing
    func addMeshAnchor(_ anchor: ARMeshAnchor) {
        guard scanState == .scanning else { return }

        // Check camera movement before accumulating new points
        guard shouldAccumulatePoints() else { return }

        // Only keep the most recent anchors to avoid memory issues
        if !meshAnchors.contains(where: { $0.identifier == anchor.identifier }) {
            meshAnchors.append(anchor)

            // Limit stored anchors to prevent ARFrame retention issues
            if meshAnchors.count > 50 {
                meshAnchors.removeFirst()
            }
        }

        // Extract points from this anchor immediately
        extractPointsFromAnchor(anchor)
        updateScanMetrics()
    }

    func updateMeshAnchor(_ anchor: ARMeshAnchor) {
        guard scanState == .scanning else { return }

        // Check camera movement before accumulating new points
        guard shouldAccumulatePoints() else { return }

        if let index = meshAnchors.firstIndex(where: { $0.identifier == anchor.identifier }) {
            meshAnchors[index] = anchor
        }

        // Extract points immediately to avoid holding ARFrame references
        extractPointsFromAnchor(anchor)
        updateScanMetrics()
    }

    // MARK: - Depth-Based Point Integration (Fallback for VIO issues)

    /// Integrate points directly from depth data (bypasses mesh anchor requirement)
    /// This is called when mesh anchors aren't available but depth data is
    func integrateDepthPoints(points: [simd_float3], normals: [simd_float3], confidence: [Float]) {
        guard scanState == .scanning else { return }

        // Check camera movement before accumulating
        guard shouldAccumulatePoints() else { return }

        // Limit total points to prevent memory issues
        let availableSpace = maxPoints - scannedPoints.count
        let pointsToAdd = min(points.count, availableSpace)

        guard pointsToAdd > 0 else {
            // At capacity - use ring buffer replacement
            for i in 0..<min(points.count, 1000) { // Add max 1000 points per frame
                let replaceIndex = currentPointIndex % maxPoints
                scannedPoints[replaceIndex] = points[i]
                if i < normals.count {
                    scannedNormals[replaceIndex] = normals[i]
                }
                if i < confidence.count {
                    scannedConfidence[replaceIndex] = confidence[i]
                }
                currentPointIndex += 1
            }
            updatePointMetrics()
            return
        }

        // Add new points
        for i in 0..<pointsToAdd {
            scannedPoints.append(points[i])
            if i < normals.count {
                scannedNormals.append(normals[i])
            }
            if i < confidence.count {
                scannedConfidence.append(confidence[i])
            }
            currentPointIndex += 1
        }

        updatePointMetrics()
        updateScanMetrics()

        // ‚úÖ NEW: Update live volume estimate
        updateLiveVolumeEstimate()
    }

    /// Check if we should accumulate new points based on camera movement
    /// Only accumulate if camera has moved significantly (rotation > 1¬∞ or translation > 1cm)
    /// ‚úÖ CRITICAL FIX: Use stored camera transform instead of accessing currentFrame (avoids ARFrame retention)
    private func shouldAccumulatePoints() -> Bool {
        // Update FPS metrics
        updateFrameMetrics()

        // ‚úÖ FIX: Use currentCameraTransform passed from delegate (no ARFrame retention!)
        guard let currentTransform = currentCameraTransform else {
            return false // No camera data yet
        }

        // Store transform for next comparison
        defer { lastCameraTransform = currentTransform }

        // Always accumulate first frame
        guard let lastTransform = lastCameraTransform else {
            return true
        }

        // Check rotation and translation thresholds
        let rotationDelta = checkRotation(lastTransform, currentTransform)
        let translationDelta = checkTranslation(lastTransform, currentTransform)

        // Accumulate if camera moved enough (rotation OR translation)
        return rotationDelta > cameraRotationThreshold || translationDelta > cameraTranslationThreshold
    }

    /// Calculate rotation delta between two transforms (dot product of forward vectors)
    private func checkRotation(_ transform1: simd_float4x4, _ transform2: simd_float4x4) -> Float {
        // Extract forward vectors (negative Z axis in ARKit)
        let forward1 = simd_float3(-transform1.columns.2.x, -transform1.columns.2.y, -transform1.columns.2.z)
        let forward2 = simd_float3(-transform2.columns.2.x, -transform2.columns.2.y, -transform2.columns.2.z)

        // Return dot product (1.0 = same direction, 0.0 = perpendicular, -1.0 = opposite)
        return simd_dot(simd_normalize(forward1), simd_normalize(forward2))
    }

    /// Calculate translation delta between two transforms (squared distance)
    private func checkTranslation(_ transform1: simd_float4x4, _ transform2: simd_float4x4) -> Float {
        let pos1 = simd_float3(transform1.columns.3.x, transform1.columns.3.y, transform1.columns.3.z)
        let pos2 = simd_float3(transform2.columns.3.x, transform2.columns.3.y, transform2.columns.3.z)

        // Return squared distance (avoiding expensive sqrt)
        let delta = pos2 - pos1
        return simd_dot(delta, delta)
    }

    /// Update FPS and timing metrics
    private func updateFrameMetrics() {
        let now = Date()

        if let lastTime = lastFrameTime {
            let deltaTime = now.timeIntervalSince(lastTime)
            frameTimeHistory.append(deltaTime)

            // Keep only recent history
            if frameTimeHistory.count > maxFrameHistory {
                frameTimeHistory.removeFirst()
            }

            // Calculate smoothed FPS
            // ‚úÖ CRASH FIX: Guard against empty frame history
            if frameTimeHistory.count > 0 {
                let avgDeltaTime = frameTimeHistory.reduce(0, +) / Double(frameTimeHistory.count)
                currentFPS = avgDeltaTime > 0 ? 1.0 / avgDeltaTime : 0.0
            } else {
                currentFPS = 0.0
            }
        }

        lastFrameTime = now
    }

    // MARK: - Point Extraction
    private func extractPointsFromAnchor(_ anchor: ARMeshAnchor) {
        let geometry = anchor.geometry
        let vertexSource = geometry.vertices
        let normalSource = geometry.normals
        let classification = geometry.classification

        let vertexCount = vertexSource.count
        let vertexStride = vertexSource.stride
        let vertexBuffer = vertexSource.buffer

        let normalStride = normalSource.stride
        let normalBuffer = normalSource.buffer

        // Calculate sampling rate to stay under maxPoints
        let samplingRate = max(1, vertexCount / 1000) // Sample ~1000 points per anchor max

        for i in stride(from: 0, to: vertexCount, by: samplingRate) {
            // Check point limit (ring buffer approach)
            if scannedPoints.count >= maxPoints {
                // Replace oldest point (ring buffer)
                let replaceIndex = currentPointIndex % maxPoints

                // Vertex
                let vertexOffset = i * vertexStride
                let vertex = vertexBuffer.contents().advanced(by: vertexOffset).assumingMemoryBound(to: SIMD3<Float>.self).pointee
                let worldPosition = anchor.transform * SIMD4<Float>(vertex.x, vertex.y, vertex.z, 1.0)

                // Normal
                let normalOffset = i * normalStride
                let normal = normalBuffer.contents().advanced(by: normalOffset).assumingMemoryBound(to: SIMD3<Float>.self).pointee
                let worldNormal = anchor.transform * SIMD4<Float>(normal.x, normal.y, normal.z, 0.0)

                // Confidence (from classification)
                let conf: Float
                if let classification = classification {
                    conf = getConfidenceFromClassification(classification, index: i)
                } else {
                    conf = 0.6 // Default confidence when classification is not available
                }

                // Apply confidence threshold filter
                if conf >= confidenceThreshold {
                    scannedPoints[replaceIndex] = simd_float3(worldPosition.x, worldPosition.y, worldPosition.z)
                    scannedNormals[replaceIndex] = simd_float3(worldNormal.x, worldNormal.y, worldNormal.z)
                    scannedConfidence[replaceIndex] = conf
                    currentPointIndex += 1
                }
            } else {
                // Still building up to maxPoints - normal accumulation
                // Vertex
                let vertexOffset = i * vertexStride
                let vertex = vertexBuffer.contents().advanced(by: vertexOffset).assumingMemoryBound(to: SIMD3<Float>.self).pointee
                let worldPosition = anchor.transform * SIMD4<Float>(vertex.x, vertex.y, vertex.z, 1.0)

                // Normal
                let normalOffset = i * normalStride
                let normal = normalBuffer.contents().advanced(by: normalOffset).assumingMemoryBound(to: SIMD3<Float>.self).pointee
                let worldNormal = anchor.transform * SIMD4<Float>(normal.x, normal.y, normal.z, 0.0)

                // Confidence (from classification)
                let conf: Float
                if let classification = classification {
                    conf = getConfidenceFromClassification(classification, index: i)
                } else {
                    conf = 0.6 // Default confidence when classification is not available
                }

                // Apply confidence threshold filter
                if conf >= confidenceThreshold {
                    scannedPoints.append(simd_float3(worldPosition.x, worldPosition.y, worldPosition.z))
                    scannedNormals.append(simd_float3(worldNormal.x, worldNormal.y, worldNormal.z))
                    scannedConfidence.append(conf)
                    currentPointIndex += 1
                }
            }
        }

        // Update metrics after point extraction
        updatePointMetrics()
        updateScanMetrics()
    }

    /// Update real-time point metrics (count, memory usage)
    private func updatePointMetrics() {
        totalPointsScanned = scannedPoints.count

        // Estimate memory usage in MB
        // Each point: 3 floats (position) + 3 floats (normal) + 1 float (confidence) = 7 floats = 28 bytes
        let bytesPerPoint = 28
        let totalBytes = scannedPoints.count * bytesPerPoint
        estimatedMemoryUsage = Double(totalBytes) / 1_048_576.0 // Convert to MB
    }

    private func getConfidenceFromClassification(_ classification: ARGeometrySource, index: Int) -> Float {
        // ARKit classification: 0=none, 1=wall, 2=floor, 3=ceiling, 4=table, etc.
        // We'll assign confidence based on classification
        let stride = classification.stride
        let buffer = classification.buffer
        let offset = index * stride
        let classValue = buffer.contents().advanced(by: offset).assumingMemoryBound(to: UInt8.self).pointee

        switch classValue {
        case 0: return 0.5  // None - medium confidence
        case 4: return 0.9  // Table - high confidence
        case 6: return 0.8  // Object - high confidence
        default: return 0.6 // Other - moderate confidence
        }
    }

    private func updateScanMetrics() {
        pointCount = scannedPoints.count

        // Calculate base confidence from point data
        let rawConfidence = scannedConfidence.isEmpty ? 0.0 : scannedConfidence.reduce(0.0, +) / Float(scannedConfidence.count)

        // ‚úÖ CRITICAL: Validate confidence result
        let baseConfidence = rawConfidence.isFinite ? rawConfidence : 0.0

        // Adjust confidence based on tracking quality
        let trackingMultiplier: Float = {
            switch trackingQuality {
            case .good: return 1.0
            case .normal: return 0.85
            case .limited: return 0.6
            }
        }()

        averageConfidence = baseConfidence * trackingMultiplier

        // Update progress (based on points collected)
        let targetPoints = 3000.0 // Realistic target for good scan
        scanProgress = min(Double(pointCount) / targetPoints, 1.0)

        // Calculate real-time coverage
        updateCoverageScore()
    }

    // ‚úÖ NEW: Update live volume estimate in real-time
    private func updateLiveVolumeEstimate() {
        guard scanState == .scanning else { return }
        guard scannedPoints.count >= 100 else {
            liveVolumeEstimate = 0.0
            volumeStability = 0.0
            volumeTrend = .unknown
            scanRecommendation = "üîÑ Mehr Daten sammeln..."
            return
        }

        // Estimate volume from current point cloud
        let result = liveVolumeEstimator.estimateVolumeLive(
            from: scannedPoints,
            confidence: scannedConfidence
        )

        liveVolumeEstimate = result.volume
        volumeStability = result.stability
        volumeTrend = liveVolumeEstimator.getTrend()

        // Update recommendation
        scanRecommendation = liveVolumeEstimator.getRecommendation(
            stability: result.stability,
            pointCount: scannedPoints.count
        )
    }

    private func updateCoverageScore() {
        guard pointCount > 100 else {
            coverageScore = 0.0
            return
        }

        // Quick coverage estimate based on point distribution
        // Group points into rough spatial grid
        let gridSize = 5
        var occupiedCells = Set<SIMD3<Int>>()

        // ‚úÖ FIX: Calculate actual bounds per component (not by distance from origin)
        guard !scannedPoints.isEmpty else {
            coverageScore = 0.0
            return
        }

        var minBounds = scannedPoints[0]
        var maxBounds = scannedPoints[0]

        for point in scannedPoints {
            minBounds.x = min(minBounds.x, point.x)
            minBounds.y = min(minBounds.y, point.y)
            minBounds.z = min(minBounds.z, point.z)

            maxBounds.x = max(maxBounds.x, point.x)
            maxBounds.y = max(maxBounds.y, point.y)
            maxBounds.z = max(maxBounds.z, point.z)
        }

        let range = maxBounds - minBounds

        // ‚úÖ CRITICAL: Guard against zero or invalid range (with small epsilon for floating point)
        let epsilon: Float = 0.001
        guard range.x.isFinite && range.y.isFinite && range.z.isFinite,
              range.x > epsilon, range.y > epsilon, range.z > epsilon else {
            // Silently skip instead of spamming console (points are too close together)
            coverageScore = 0.0
            return
        }

        let cellSize = simd_float3(
            range.x / Float(gridSize),
            range.y / Float(gridSize),
            range.z / Float(gridSize)
        )

        // ‚úÖ CRITICAL: Verify cellSize is valid
        guard cellSize.x.isFinite && cellSize.y.isFinite && cellSize.z.isFinite,
              cellSize.x > 0, cellSize.y > 0, cellSize.z > 0 else {
            print("‚ö†Ô∏è Invalid cellSize for coverage calculation: \(cellSize)")
            coverageScore = 0.0
            return
        }

        // Count occupied cells
        for point in scannedPoints {
            // ‚úÖ CRITICAL: Skip invalid points
            guard point.x.isFinite && point.y.isFinite && point.z.isFinite else {
                continue
            }

            let relative = point - minBounds

            // ‚úÖ CRITICAL: Guard division and Int conversion
            guard relative.x.isFinite && relative.y.isFinite && relative.z.isFinite else {
                continue
            }

            let cellX = min(max(0, Int((relative.x / cellSize.x).rounded(.down))), gridSize - 1)
            let cellY = min(max(0, Int((relative.y / cellSize.y).rounded(.down))), gridSize - 1)
            let cellZ = min(max(0, Int((relative.z / cellSize.z).rounded(.down))), gridSize - 1)

            occupiedCells.insert(SIMD3<Int>(cellX, cellY, cellZ))
        }

        let totalCells = gridSize * gridSize * gridSize

        // Calculate coverage score (gridSize is always > 0, so totalCells is always > 0)
        coverageScore = Float(occupiedCells.count) / Float(totalCells)
    }

    // MARK: - Processing

    /// ‚úÖ EMERGENCY FIX: Recenter points before TSDF to fix empty mesh
    private func recenterPointsBeforeTSDF() {
        print("üîß Recentering points for TSDF...")

        guard !scannedPoints.isEmpty else {
            print("   ‚ùå No points to recenter")
            return
        }

        // Calculate center
        var center = SIMD3<Float>.zero
        for point in scannedPoints {
            // ‚úÖ CRITICAL: Skip invalid points
            guard point.x.isFinite && point.y.isFinite && point.z.isFinite else {
                continue
            }
            center += point
        }

        // ‚úÖ CRITICAL: Guard against division by zero or invalid count
        let validCount = Float(scannedPoints.count)
        guard validCount > 0 else {
            print("   ‚ùå No valid points to recenter")
            return
        }

        center /= validCount

        // ‚úÖ CRITICAL: Verify center is valid
        guard center.x.isFinite && center.y.isFinite && center.z.isFinite else {
            print("   ‚ùå ERROR: Calculated center is NaN/Infinite: \(center)")
            return
        }

        // Calculate extent
        var minPoint = scannedPoints[0]
        var maxPoint = scannedPoints[0]

        for point in scannedPoints {
            // ‚úÖ CRITICAL: Skip invalid points
            guard point.x.isFinite && point.y.isFinite && point.z.isFinite else {
                continue
            }

            minPoint = SIMD3<Float>(
                min(minPoint.x, point.x),
                min(minPoint.y, point.y),
                min(minPoint.z, point.z)
            )
            maxPoint = SIMD3<Float>(
                max(maxPoint.x, point.x),
                max(maxPoint.y, point.y),
                max(maxPoint.z, point.z)
            )
        }

        let extent = maxPoint - minPoint

        // ‚úÖ CRITICAL: Verify extent is valid
        guard extent.x.isFinite && extent.y.isFinite && extent.z.isFinite else {
            print("   ‚ùå ERROR: Calculated extent is NaN/Infinite: \(extent)")
            return
        }

        print("   üìä Original bounds:")
        print("      Center: \(center)")
        print("      Extent: \(extent) meters")

        // ‚úÖ CRITICAL FIX: Recenter all points around origin
        for i in 0..<scannedPoints.count {
            scannedPoints[i] -= center
        }

        // Also recenter normals if needed
        // (normals are directions, so no change needed)

        print("   ‚úÖ Points recentered around (0,0,0)")
        print("   üìä New extent: \(extent) meters (unchanged)")

        // Check if points fit in TSDF grid
        let tsdfSize: Float = 0.6 // Increased from 0.32 (see Patch 4)

        if extent.x > tsdfSize || extent.y > tsdfSize || extent.z > tsdfSize {
            print("   ‚ö†Ô∏è WARNING: Points extent (\(extent)) exceeds TSDF grid (\(tsdfSize)m)")

            let maxExtent = max(extent.x, extent.y, extent.z)

            // ‚úÖ CRITICAL: Guard against invalid scale calculation
            guard maxExtent.isFinite && maxExtent > 0 else {
                print("   ‚ùå ERROR: Invalid maxExtent for scaling: \(maxExtent)")
                return
            }

            print("   üìè Recommended TSDF size: \(maxExtent * 1.2)m")

            // ‚úÖ EMERGENCY FIX: Scale points to fit
            let scale = tsdfSize / (maxExtent * 1.2)

            // ‚úÖ CRITICAL: Verify scale is valid
            guard scale.isFinite && scale > 0 else {
                print("   ‚ùå ERROR: Invalid scale calculated: \(scale)")
                return
            }

            for i in 0..<scannedPoints.count {
                scannedPoints[i] *= scale
            }
            print("   ‚úÖ Points scaled by \(scale) to fit in TSDF grid")
        }
    }

    /// Async version to avoid blocking UI
    private func processMeshDataAsync(withMeshAnchors providedMeshAnchors: [ARMeshAnchor]) async {
        print("   üîß processMeshDataAsync() started with \(providedMeshAnchors.count) mesh anchors")

        // ‚úÖ CRITICAL FIX: If object is selected, use ONLY that object's data
        var finalPoints: [simd_float3]
        var finalNormals: [simd_float3]
        var finalConfidence: [Float]

        if isObjectSelected, let selected = selectedObject {
            print("   üéØ OBJECT SELECTED: Using isolated object data")
            print("      Object points: \(selected.points.count)")
            print("      Object confidence: \(selected.confidence)")
            print("      Object bounding box: \(selected.boundingBox.size)")

            finalPoints = selected.points
            finalNormals = selected.normals
            // Generate confidence values for selected points (all high confidence since they passed selection)
            finalConfidence = Array(repeating: selected.confidence, count: selected.points.count)

            print("   ‚úÖ Processing ONLY selected object (\(finalPoints.count) points)")
        } else if isMultiScanMode, let merged = multiScanManager.mergeScans() {
            print("   üìä Multi-scan: Merging scans...")
            finalPoints = merged.points
            finalNormals = merged.normals
            finalConfidence = merged.confidence
        } else {
            print("   üìä Single scan: Using scanned data (NO OBJECT SELECTED)")
            print("      ‚ö†Ô∏è WARNING: Measuring entire scene - tap to select specific object!")
            finalPoints = scannedPoints
            finalNormals = scannedNormals
            finalConfidence = scannedConfidence
        }

        print("   üìà Data prepared: \(finalPoints.count) points")

        guard !finalPoints.isEmpty else {
            print("   ‚ùå No points captured!")
            await MainActor.run {
                scanState = .error("Keine Datenpunkte erfasst")
            }
            return
        }

        // ü§ñ AI-Enhanced Mesh Refinement (optional, in background)
        var aiQuality: Float = 0.8  // Default quality

        if enableAIRefinement {
            print("   üé® Starting AI mesh refinement...")
            let startTime = Date()

            // Use balanced mode for better performance (not aiEnhanced)
            let refinementOptions = AdvancedRefinementOptions.balanced()

            // Run in background
            print("   ‚öôÔ∏è Creating detached task for AI processing...")
            let (refinedPoints, refinedNormals, refinementQuality) = await Task.detached {
                print("      üî¨ Detached task running - calling refineWithAI()")
                let result = AdvancedMeshRefinement.refineWithAI(
                    points: finalPoints,
                    normals: finalNormals,
                    options: refinementOptions
                )
                print("      ‚úì refineWithAI() completed")
                return result
            }.value

            let duration = Date().timeIntervalSince(startTime)
            print("   ‚è±Ô∏è AI Refinement took \(String(format: "%.2f", duration))s")

            // Use refined data
            finalPoints = refinedPoints
            finalNormals = refinedNormals ?? finalNormals
            aiQuality = refinementQuality

            // Safety: Ensure aiQuality is finite before converting to Int
            let safeAiQuality = aiQuality.isFinite ? aiQuality : 0.5
            let aiQualityPercent = safeAiQuality.isFinite ? Int(safeAiQuality * 100) : 50

            print("   ‚ú® AI Refinement complete: Quality improved to \(aiQualityPercent)%")
        } else {
            print("   ‚ö†Ô∏è AI Refinement disabled - using raw data")
        }

        // ‚úÖ CRASH FIX: Skip TSDF reconstruction (causes crashes)
        if !enableTSDFReconstruction {
            print("   ‚ÑπÔ∏è TSDF reconstruction disabled - using direct mesh calculation")

            // Use provided mesh anchors (already captured at scan completion)
            let meshAnchors = providedMeshAnchors
            let selectedObj = await MainActor.run { self.selectedObject }
            let objSelected = await MainActor.run { self.isObjectSelected }

            guard !meshAnchors.isEmpty else {
                await MainActor.run {
                    scanState = .error("Keine Mesh-Daten verf√ºgbar")
                }
                return
            }

            // Use mesh-based volume calculation (reliable)
            let (meshVolumeResult, meshQualityDescription) = self.calculateMeshVolumeSync(
                meshAnchors: meshAnchors,
                selectedObject: selectedObj,
                isObjectSelected: objSelected
            )

            guard let volumeResult = meshVolumeResult else {
                await MainActor.run {
                    scanState = .error("Volumenberechnung fehlgeschlagen")
                }
                return
            }

            // Calculate weight
            let selectedMat = await MainActor.run { self.selectedMaterial }
            let packingFactor = selectedMat.packingFactor ?? 1.0
            let weight = volumeResult.volume_cm3 * (selectedMat.density * packingFactor)

            // Update UI on main thread
            await MainActor.run {
                self.volume_cm3 = volumeResult.volume_cm3
                self.weight_g = weight
                self.qualityScore = volumeResult.quality.qualityScore
                self.confidence = volumeResult.quality.qualityScore
                self.meshVolumeResult = volumeResult
                self.meshQualityDescription = meshQualityDescription
                self.can3DExport = true
                self.scanState = .completed

                print("   ‚úÖ Direct mesh calculation complete:")
                print("      Volume: \(volumeResult.volume_cm3) cm¬≥")
                print("      Weight: \(weight) g")
                print("      Quality: \(volumeResult.quality.qualityScore)")
            }

            return
        }

        // ‚ö†Ô∏è LEGACY: TSDF path (disabled by default due to crashes)
        // ‚úÖ FIX EMPTY MESH: Recenter points before TSDF
        recenterPointsBeforeTSDF()

        // üéØ TSDF Volumetric Reconstruction (High Accuracy)
        print("   üèóÔ∏è Starting TSDF reconstruction...")
        let tsdfStartTime = Date()

        // Downsample for performance (GPU-accelerated if available)
        print("   üìä Downsampling point cloud...")
        var downsampledPoints: [SIMD3<Float>]

        // Try GPU acceleration first, fallback to CPU
        if let metalProcessor = MetalPointCloudProcessor(),
           let downsampled = metalProcessor.downsample(
               points: finalPoints,
               normals: finalNormals,
               confidences: finalConfidence,
               voxelSize: 0.005  // 5mm voxels
           ) {
            downsampledPoints = downsampled.points
            print("   ‚úì GPU Downsampled: \(finalPoints.count) ‚Üí \(downsampledPoints.count) points")
        } else {
            // Fallback to CPU downsampling
            downsampledPoints = PointCloudUtils.voxelDownsample(
                points: finalPoints,
                voxelSize: 0.005  // 5mm voxels
            )
            print("   ‚úì CPU Downsampled: \(finalPoints.count) ‚Üí \(downsampledPoints.count) points")
        }

        // üßπ Denoise point cloud before TSDF integration (ML-enhanced with fallback)
        print("   üßπ Denoising point cloud...")
        let denoiseStartTime = Date()
        let denoiser = PointCloudDenoiserCoreML()  // Uses ML model if available, else fast VoxelSmoothingDenoiser
        let denoisedPoints = denoiser.denoise(points: downsampledPoints)
        let denoiseDuration = Date().timeIntervalSince(denoiseStartTime)
        let denoiseMethod = denoiser.usedMLModel ? "ML" : "Voxel"
        print("   ‚úì Denoised (\(denoiseMethod)): \(denoisedPoints.count) points in \(String(format: "%.3f", denoiseDuration))s")

        // Calculate bounding box with margin
        guard let (minP, maxP) = PointCloudUtils.boundingBox(points: denoisedPoints) else {
            print("   ‚ùå Failed to calculate bounding box")
            await MainActor.run {
                scanState = .error("Fehler beim Berechnen der Begrenzungsbox")
            }
            return
        }

        // ‚úÖ EMERGENCY FIX: Increase grid size from 0.32m to 0.6m minimum
        let margin: Float = 0.1  // 10cm margin (was 5cm)
        let gridOrigin = minP - SIMD3<Float>(repeating: margin)
        var gridSize = (maxP - minP) + SIMD3<Float>(repeating: margin * 2)

        // ‚úÖ CRITICAL FIX: Ensure minimum grid size of 0.6m (was 0.32m - too small!)
        let minGridSize: Float = 0.6
        gridSize.x = max(gridSize.x, minGridSize)
        gridSize.y = max(gridSize.y, minGridSize)
        gridSize.z = max(gridSize.z, minGridSize)

        // Create TSDF volume with adaptive grid size
        let voxelSize: Float = 0.005  // 5mm resolution (was 4mm)

        // ‚úÖ CRITICAL FIX: Guard against NaN/Infinite values
        guard gridSize.x.isFinite && gridSize.y.isFinite && gridSize.z.isFinite else {
            print("   ‚ùå ERROR: Grid size contains NaN/Infinite values: \(gridSize)")
            await MainActor.run {
                scanState = .error("Ung√ºltige Grid-Gr√∂√üe erkannt")
            }
            return
        }

        // ‚úÖ CRITICAL: Validate voxelSize before division
        guard voxelSize > 0 && voxelSize.isFinite else {
            print("   ‚ùå ERROR: Invalid voxel size: \(voxelSize)")
            await MainActor.run {
                scanState = .error("Ung√ºltige Voxel-Gr√∂√üe")
            }
            return
        }

        // ‚úÖ CRITICAL: Calculate dimensions with validation
        let dimXFloat = (gridSize.x / voxelSize).rounded(.up)
        let dimYFloat = (gridSize.y / voxelSize).rounded(.up)
        let dimZFloat = (gridSize.z / voxelSize).rounded(.up)

        // ‚úÖ CRITICAL: Verify dimension values before Int conversion
        guard dimXFloat.isFinite && dimYFloat.isFinite && dimZFloat.isFinite else {
            print("   ‚ùå ERROR: Dimension calculations produced NaN/Infinite")
            await MainActor.run {
                scanState = .error("Ung√ºltige Dimensionsberechnung")
            }
            return
        }

        let dimX = min(256, max(64, Int(dimXFloat)))
        let dimY = min(256, max(64, Int(dimYFloat)))
        let dimZ = min(256, max(64, Int(dimZFloat)))

        print("   üìê TSDF Grid: \(dimX)√ó\(dimY)√ó\(dimZ), voxel size: \(voxelSize*1000)mm")

        let tsdf = TSDFVolume(
            dimX: dimX, dimY: dimY, dimZ: dimZ,
            voxelSize: voxelSize,
            origin: gridOrigin,
            truncation: voxelSize * 5.0
        )

        // Integrate denoised points into TSDF
        print("   üîÑ Integrating cleaned points into TSDF...")
        tsdf.integratePointsApprox(points: denoisedPoints, weight: 1.0)

        // Extract mesh
        print("   üé® Extracting mesh via marching cubes...")
        var (tsdfVertices, _, tsdfTriangles) = tsdf.extractMesh(isovalue: 0.0)
        print("   ‚úì Mesh extracted: \(tsdfVertices.count) vertices, \(tsdfTriangles.count/3) triangles")

        // üîß Mesh decimation: Reduce triangle count while preserving quality
        let initialTriangleCount = tsdfTriangles.count / 3
        if initialTriangleCount > 20000 {
            print("   üîß Decimating mesh to reduce complexity...")
            let decimator = QuadricMeshDecimator(aggressiveness: 7.0, verbose: true)

            // Convert triangles to SIMD3<Int32>
            var triangleTuples: [SIMD3<Int32>] = []
            for i in stride(from: 0, to: tsdfTriangles.count, by: 3) {
                triangleTuples.append(SIMD3<Int32>(
                    Int32(tsdfTriangles[i]),
                    Int32(tsdfTriangles[i+1]),
                    Int32(tsdfTriangles[i+2])
                ))
            }

            // Target: 50% reduction for very large meshes, 70% for moderate
            let targetTriangleCount = initialTriangleCount > 50000 ? initialTriangleCount / 2 : Int(Float(initialTriangleCount) * 0.7)

            let decimated = decimator.simplify(
                vertices: tsdfVertices,
                triangles: triangleTuples,
                targetCount: targetTriangleCount
            )

            // Convert back to UInt32 array
            tsdfVertices = decimated.vertices
            tsdfTriangles = decimated.triangles.flatMap { [UInt32($0.x), UInt32($0.y), UInt32($0.z)] }

            print("   ‚úÖ Mesh decimated: \(initialTriangleCount) ‚Üí \(decimated.triangles.count) triangles")
        } else {
            print("   ‚ÑπÔ∏è Skipping decimation (mesh already optimized: \(initialTriangleCount) triangles)")
        }

        let tsdfDuration = Date().timeIntervalSince(tsdfStartTime)
        print("   ‚è±Ô∏è TSDF reconstruction took \(String(format: "%.2f", tsdfDuration))s")

        // üìê Accurate mesh-based volume calculation (tetrahedralization)
        print("   üìê Computing accurate mesh volume via tetrahedralization...")
        let (signedVol, meshVolumeM3) = MeshVolume.computeVolumeWithCentroid(
            vertices: tsdfVertices,
            triangles: tsdfTriangles
        )
        let meshVolumeMl = MeshVolume.cubicMetersToMilliliters(meshVolumeM3)
        print("   ‚úì Mesh-based volume: \(String(format: "%.2f", meshVolumeMl)) ml (signed: \(String(format: "%.2f", signedVol)))")

        // Validate mesh quality
        let warnings = MeshVolume.validateMeshTopology(vertices: tsdfVertices, triangles: tsdfTriangles)
        if !warnings.isEmpty {
            print("   ‚ö†Ô∏è Mesh validation warnings:")
            for warning in warnings.prefix(3) {
                print("      - \(warning)")
            }
        }

        // Calculate surface area for quality metrics
        let surfaceArea = MeshVolume.computeSurfaceArea(vertices: tsdfVertices, triangles: tsdfTriangles)
        print("   üìè Surface area: \(String(format: "%.4f", surfaceArea)) m¬≤")

        // Quick voxel-based volume estimate (for comparison)
        let quickVolumeM3 = PointCloudUtils.voxelCountVolume(
            points: downsampledPoints,
            voxelSize: voxelSize
        )
        let quickVolumeMl = quickVolumeM3 * 1_000_000
        print("   üìä Voxel volume estimate: \(String(format: "%.2f", quickVolumeMl)) ml")
        print("   üìä Volume difference: \(String(format: "%.1f", abs(meshVolumeMl - quickVolumeMl))) ml (\(String(format: "%.1f", abs(meshVolumeMl - quickVolumeMl) / max(meshVolumeMl, 1) * 100))%)")

        // Export TSDF mesh and point clouds for debugging (optional, in DEBUG mode)
        #if DEBUG
        let exportVertices = tsdfVertices  // Capture mesh data outside Task
        let exportTriangles = tsdfTriangles
        let exportDownsampled = downsampledPoints  // Raw downsampled points
        let exportDenoised = denoisedPoints        // Cleaned points
        Task.detached {
            let documentsURL = FileManager.default.urls(
                for: .documentDirectory,
                in: .userDomainMask
            )[0]

            let timestamp = Date().timeIntervalSince1970

            // Export TSDF mesh (with triangles)
            let meshPlyURL = documentsURL.appendingPathComponent("tsdf_mesh_\(timestamp).ply")
            try? PointCloudUtils.writePLY(vertices: exportVertices, triangles: exportTriangles, url: meshPlyURL)
            print("   üíæ TSDF mesh PLY: \(meshPlyURL.lastPathComponent)")

            // Export raw downsampled points (before denoising)
            let rawPlyURL = documentsURL.appendingPathComponent("points_raw_\(timestamp).ply")
            try? PointCloudUtils.writePLY(points: exportDownsampled, url: rawPlyURL)
            print("   üíæ Raw points PLY: \(rawPlyURL.lastPathComponent)")

            // Export denoised points (after denoising)
            let denoisedPlyURL = documentsURL.appendingPathComponent("points_denoised_\(timestamp).ply")
            try? PointCloudUtils.writePLY(points: exportDenoised, url: denoisedPlyURL)
            print("   üíæ Denoised points PLY: \(denoisedPlyURL.lastPathComponent)")

            print("   üìÅ All PLY files saved to Documents folder")
        }
        #endif

        print("   üîÑ Starting final processing (all in background)...")

        // ALL CPU-INTENSIVE WORK IN BACKGROUND WITH TIMEOUT
        let processingResult: ProcessingResult?

        do {
            processingResult = try await withThrowingTaskGroup(of: ProcessingResult?.self) { group in
                group.addTask {
                    try Task.checkCancellation()

                    return await Task.detached { [weak self] () -> ProcessingResult? in
                        guard let self = self else { return nil }

                        print("      üîß Background: Starting heavy computations...")

                        // 1. Detect plane (CPU-intensive)
                        print("      1Ô∏è‚É£ Detecting table plane...")
                        let planeHeight = self.detectTablePlaneSync(from: finalPoints, normals: finalNormals)

            // 2. Calculate volume (VERY CPU-intensive)
            print("      2Ô∏è‚É£ Calculating volume...")
            let material = await MainActor.run { self.selectedMaterial }
            guard let volumeResult = self.volumeEstimator.estimateVolume(
                from: finalPoints,
                normals: finalNormals,
                materialCategory: material.category,
                planeHeight: planeHeight
            ) else {
                print("      ‚ùå Volume calculation failed")
                return nil
            }

            // 3. Calculate weight (BEFORE calibration - will be recalculated with calibrated volume on main thread)
            print("      3Ô∏è‚É£ Calculating initial weight...")
            let density = await MainActor.run { self.selectedMaterial.density }
            let weight_g = Double(volumeResult.volume_cm3) * density

            // 4. Evaluate accuracy (CPU-intensive)
            print("      4Ô∏è‚É£ Evaluating accuracy...")
            let (accuracyPercentage, accuracyDescription, accuracyColor) = self.evaluateAccuracySync(
                volumeResult: volumeResult,
                points: finalPoints,
                confidence: finalConfidence
            )

            // 5. Spatial analysis (CPU-intensive)
            print("      5Ô∏è‚É£ Performing spatial analysis...")
            let symmetryScore = self.performSpatialAnalysisSync(points: finalPoints, boundingBox: volumeResult.boundingBox)

            // 6. Calculate mesh volume (VERY CPU-intensive)
            print("      6Ô∏è‚É£ Calculating mesh volume...")
            let meshAnchors = await MainActor.run { self.meshAnchors }
            let selectedObj = await MainActor.run { self.selectedObject }
            let objSelected = await MainActor.run { self.isObjectSelected }
            let (meshVolumeResult, meshQualityDescription) = self.calculateMeshVolumeSync(
                meshAnchors: meshAnchors,
                selectedObject: selectedObj,
                isObjectSelected: objSelected
            )

            // Use mesh volume if more accurate (still uncalibrated at this point)
            var finalVolume = Double(volumeResult.volume_cm3)
            if let meshResult = meshVolumeResult, meshResult.quality.qualityScore > 0.7 {
                finalVolume = meshResult.volume_cm3
                print("      ‚úÖ Using mesh-based volume (higher quality)")
            }

            print("      ‚ú® All background computations complete!")

            // Return all results
            return ProcessingResult(
                volume_cm3: finalVolume,
                weight_g: weight_g,
                dimensions: SIMD3<Float>(volumeResult.width_m * 100, volumeResult.height_m * 100, volumeResult.depth_m * 100),
                detectedPlaneHeight: planeHeight,
                accuracyPercentage: accuracyPercentage,
                accuracyDescription: accuracyDescription,
                accuracyColor: accuracyColor,
                symmetryScore: symmetryScore,
                meshVolumeResult: meshVolumeResult,
                meshQualityDescription: meshQualityDescription,
                aiQuality: aiQuality
            )
                    }.value
                }

                // Wait for result with reasonable timeout
                for try await result in group {
                    return result
                }

                return nil
            }
        } catch {
            print("      ‚ùå Processing error: \(error)")
            processingResult = nil
        }

        // FAST UI UPDATE ON MAIN THREAD
        await MainActor.run {
            print("      üì± Main thread: Updating UI with results...")

            guard let result = processingResult else {
                scanState = .error("Volumenberechnung fehlgeschlagen")
                print("      ‚ùå Processing failed")
                return
            }

            // ‚úÖ Apply calibration if available (uses class property)
            let calibratedDimensions = calibrationManager.calibrateDimensions(result.dimensions)

            // Calculate calibrated volume (volume scales cubically with linear dimensions)
            let volumeScaleFactor: Float
            if let factor = calibrationManager.calibrationFactor {
                volumeScaleFactor = factor * factor * factor  // V ‚àù L¬≥
            } else {
                volumeScaleFactor = 1.0
            }
            let calibratedVolume = Float(result.volume_cm3) * volumeScaleFactor

            // ‚úÖ CRASH FIX: Validate calibrated values before proceeding
            guard calibratedVolume.isFinite && calibratedVolume >= 0 else {
                print("      ‚ùå ERROR: Calibrated volume is invalid (NaN/Infinite): \(calibratedVolume)")
                scanState = .error("Ung√ºltiges Volumen berechnet")
                return
            }

            guard calibratedDimensions.x.isFinite && calibratedDimensions.y.isFinite && calibratedDimensions.z.isFinite else {
                print("      ‚ùå ERROR: Calibrated dimensions contain NaN/Infinite: \(calibratedDimensions)")
                scanState = .error("Ung√ºltige Dimensionen berechnet")
                return
            }

            if calibrationManager.isCalibrated {
                print("      ‚úÖ Calibration applied: \(String(format: "%.2f", result.volume_cm3))ml ‚Üí \(String(format: "%.2f", calibratedVolume))ml")
                print("      ‚úÖ Dimensions calibrated: \(result.dimensions) ‚Üí \(calibratedDimensions)")
            }

            // Recalculate weight with calibrated volume
            let calibratedWeight = Double(calibratedVolume) * selectedMaterial.density

            // ‚úÖ CRASH FIX: Validate weight is finite
            guard calibratedWeight.isFinite && calibratedWeight >= 0 else {
                print("      ‚ùå ERROR: Calibrated weight is invalid (NaN/Infinite): \(calibratedWeight)")
                scanState = .error("Ung√ºltiges Gewicht berechnet")
                return
            }

            // Update all UI properties at once (all values validated)
            self.volume_cm3 = Double(calibratedVolume)
            self.weight_g = calibratedWeight
            self.dimensions = calibratedDimensions
            self.detectedPlaneHeight = result.detectedPlaneHeight
            self.accuracyPercentage = result.accuracyPercentage
            self.accuracyDescription = result.accuracyDescription
            self.accuracyColor = result.accuracyColor
            self.symmetryScore = result.symmetryScore
            self.meshVolumeResult = result.meshVolumeResult
            self.meshQualityDescription = result.meshQualityDescription
            self.qualityScore = max(qualityScore, Double(result.aiQuality))
            self.can3DExport = !meshAnchors.isEmpty

            // Set state to completed
            self.scanState = .completed

            print("      ‚úÖ UI updated - scan complete!")
        }

        print("   üéØ processMeshDataAsync() finished")
    }

    // MARK: - Processing Result Structure

    private struct ProcessingResult {
        let volume_cm3: Double
        let weight_g: Double
        let dimensions: SIMD3<Float>
        let detectedPlaneHeight: Float?
        let accuracyPercentage: Double
        let accuracyDescription: String
        let accuracyColor: String
        let symmetryScore: Float
        let meshVolumeResult: MeshVolumeResult?
        let meshQualityDescription: String
        let aiQuality: Float
    }

    // MARK: - Background-Safe Sync Methods (nonisolated)

    /// Detect table plane without accessing MainActor properties
    nonisolated private func detectTablePlaneSync(from points: [simd_float3], normals: [simd_float3]) -> Float? {
        // Find horizontal surfaces (table/floor)
        var horizontalPoints: [simd_float3] = []

        for i in 0..<min(points.count, normals.count) {
            let normal = normals[i]
            // Check if normal is pointing up (dot product with up vector)
            if abs(dot(normal, simd_float3(0, 1, 0))) > 0.9 {
                horizontalPoints.append(points[i])
            }
        }

        if !horizontalPoints.isEmpty {
            // Find most common Y value (histogram)
            let yValues = horizontalPoints.map { $0.y }

            // ‚úÖ CRITICAL: Guard division and validate result
            guard yValues.count > 0 else { return nil }
            let avgY = yValues.reduce(0, +) / Float(yValues.count)

            // ‚úÖ CRITICAL: Verify result is valid
            guard avgY.isFinite else {
                print("‚ö†Ô∏è Plane height calculation produced NaN/Infinite")
                return nil
            }

            return avgY
        }

        return nil
    }

    /// Evaluate accuracy without MainActor access
    nonisolated private func evaluateAccuracySync(
        volumeResult: VolumeResult,
        points: [simd_float3],
        confidence: [Float]
    ) -> (accuracyPercentage: Double, accuracyDescription: String, accuracyColor: String) {
        // Simple quality score based on point count and confidence
        let avgConfidence = confidence.isEmpty ? 0.5 : confidence.reduce(0, +) / Float(confidence.count)

        // ‚úÖ CRITICAL: Validate avgConfidence
        let safeAvgConfidence = avgConfidence.isFinite ? avgConfidence : 0.5

        let pointDensity = min(Float(points.count) / 5000.0, 1.0)

        // ‚úÖ CRITICAL: Validate pointDensity
        let safePointDensity = pointDensity.isFinite ? pointDensity : 0.0

        let qualityScore = (safeAvgConfidence + safePointDensity) / 2.0

        // ‚úÖ CRITICAL: Validate qualityScore before using
        let safeQualityScore = qualityScore.isFinite ? qualityScore : 0.5

        let accuracyPercentage = Double(safeQualityScore * 100)

        let description: String
        let color: String

        if qualityScore > 0.8 {
            description = "Ausgezeichnet"
            color = "green"
        } else if qualityScore > 0.6 {
            description = "Gut"
            color = "orange"
        } else {
            description = "Akzeptabel"
            color = "yellow"
        }

        return (accuracyPercentage, description, color)
    }

    /// Spatial analysis without MainActor access
    nonisolated private func performSpatialAnalysisSync(points: [simd_float3], boundingBox: BoundingBox) -> Float {
        // Calculate simple symmetry score
        guard points.count > 10 else { return 0.5 }

        // Calculate center of mass
        let centerOfMass = points.reduce(simd_float3.zero, +) / Float(points.count)

        // ‚úÖ CRITICAL: Validate center of mass
        guard centerOfMass.x.isFinite && centerOfMass.y.isFinite && centerOfMass.z.isFinite else {
            print("‚ö†Ô∏è Center of mass calculation produced NaN/Infinite")
            return 0.5
        }

        // Calculate variance from center
        let variances = points.map { point -> Float in
            let diff = point - centerOfMass
            return simd_length(diff)
        }

        // ‚úÖ CRITICAL: Guard division and validate
        guard variances.count > 0 else { return 0.5 }
        let avgVariance = variances.reduce(0, +) / Float(variances.count)
        let maxVariance = variances.max() ?? 0.1

        // ‚úÖ CRITICAL: Validate variance values
        guard avgVariance.isFinite && maxVariance.isFinite && maxVariance > 0 else {
            print("‚ö†Ô∏è Variance calculation produced NaN/Infinite")
            return 0.5
        }

        // Symmetry score: lower variance = more symmetric
        let ratio = avgVariance / maxVariance

        // ‚úÖ CRITICAL: Validate ratio
        guard ratio.isFinite else {
            print("‚ö†Ô∏è Symmetry ratio produced NaN/Infinite")
            return 0.5
        }

        let symmetryScore = 1.0 - min(ratio, 1.0)

        return symmetryScore
    }

    /// Calculate mesh volume without MainActor access
    /// ‚úÖ ENHANCED: Now uses smoothed mesh for better accuracy
    /// ‚úÖ IMPROVED: Uses ImprovedMeshFilter to remove background
    /// ‚úÖ CRITICAL FIX: Uses selected object if available
    nonisolated private func calculateMeshVolumeSync(meshAnchors: [ARMeshAnchor], selectedObject: SelectedObject? = nil, isObjectSelected: Bool = false) -> (MeshVolumeResult?, String) {
        // ‚úÖ CRITICAL FIX: Use selected object's mesh if available
        let anchorsToProcess: [ARMeshAnchor]
        if isObjectSelected, let selected = selectedObject, let meshAnchor = selected.meshAnchor {
            // Mesh-based selection: use the specific mesh anchor
            anchorsToProcess = [meshAnchor]
        } else {
            // Depth-based selection or no selection: use all mesh anchors
            guard !meshAnchors.isEmpty else { return (nil, "Keine Mesh-Daten") }
            anchorsToProcess = meshAnchors
        }

        // ‚úÖ NEW: Apply mesh filtering to remove background/table
        print("   üîß Applying ImprovedMeshFilter to remove background...")
        let meshFilter = ImprovedMeshFilter(config: .lenient())  // ‚úÖ Use lenient config
        let filteredMeshes = meshFilter.filterObjectMeshes(
            meshAnchors: anchorsToProcess,
            objectCenter: selectedObject?.center,
            planeHeight: nil  // Auto-detect from selection
        )

        // If filtering removed everything, fall back to original anchors
        let finalAnchors: [ARMeshAnchor]
        if filteredMeshes.isEmpty {
            print("   ‚ö†Ô∏è Mesh filtering removed all geometry - using original anchors")
            finalAnchors = anchorsToProcess
        } else {
            print("   ‚úì Mesh filtered: \(filteredMeshes.count) filtered anchors")
            // Use filtered mesh anchors
            finalAnchors = filteredMeshes.map { $0.anchor }
        }

        // Calculate precise volume from mesh with enhanced smoothing
        // Use moderate smoothing for balanced speed and accuracy
        let smoothingConfig = MeshSmoothingEngine.SmoothingConfiguration(iterations: 3, lambda: 0.5, preserveFeatures: true)
        if let enhancedResult = MeshVolumeCalculator.calculateVolumeEnhanced(
            from: finalAnchors,  // ‚úÖ Use filtered anchors instead
            applySmoothing: true,
            smoothingConfig: smoothingConfig
        ) {
            // Convert EnhancedVolumeResult to MeshVolumeResult for compatibility
            let meshResult = MeshVolumeResult(
                volume_m3: enhancedResult.volume_m3,
                volume_cm3: enhancedResult.volume_cm3,
                surfaceArea_m2: enhancedResult.surfaceArea_m2,
                method: enhancedResult.method,
                quality: MeshVolumeResult.MeshQuality(
                    isWatertight: enhancedResult.quality.isWatertight,
                    hasNormals: enhancedResult.quality.hasNormals,
                    triangleDensity: enhancedResult.quality.triangleDensity,
                    qualityScore: enhancedResult.quality.qualityScore
                ),
                triangleCount: enhancedResult.triangleCount,
                isClosed: enhancedResult.isClosed
            )

            // Use enhanced quality description (create manually to avoid MainActor)
            let score = enhancedResult.quality.qualityScore
            let qualityDesc: String
            switch score {
            case 0.9...1.0: qualityDesc = "Exzellent (\(Int(score * 100))%)"
            case 0.7..<0.9: qualityDesc = "Sehr gut (\(Int(score * 100))%)"
            case 0.5..<0.7: qualityDesc = "Gut (\(Int(score * 100))%)"
            case 0.3..<0.5: qualityDesc = "Befriedigend (\(Int(score * 100))%)"
            default: qualityDesc = "Ungen√ºgend (\(Int(score * 100))%)"
            }
            return (meshResult, qualityDesc)
        }

        return (nil, "Berechnung fehlgeschlagen")
    }

    // MARK: - 3D Model Processing (MainActor versions)

    private func calculateMeshVolume() {
        // ‚úÖ CRITICAL FIX: Use selected object's mesh if available
        let anchorsToProcess: [ARMeshAnchor]
        if isObjectSelected, let selected = selectedObject, let meshAnchor = selected.meshAnchor {
            print("   üéØ Using selected object's mesh anchor for volume calculation")
            anchorsToProcess = [meshAnchor]
        } else {
            print("   üìä Using all mesh anchors (depth-based selection or no selection)")
            guard !meshAnchors.isEmpty else { return }
            anchorsToProcess = meshAnchors
        }

        // Calculate precise volume from mesh with enhanced smoothing
        // ‚úÖ ENHANCED: Now uses smoothed mesh for better accuracy (¬±5-10% vs ¬±15-30%)
        let smoothingConfig = MeshSmoothingEngine.SmoothingConfiguration(iterations: 3, lambda: 0.5, preserveFeatures: true)
        if let enhancedResult = MeshVolumeCalculator.calculateVolumeEnhanced(
            from: anchorsToProcess,
            applySmoothing: true,
            smoothingConfig: smoothingConfig
        ) {
            // Convert to standard format
            let meshResult = MeshVolumeResult(
                volume_m3: enhancedResult.volume_m3,
                volume_cm3: enhancedResult.volume_cm3,
                surfaceArea_m2: enhancedResult.surfaceArea_m2,
                method: enhancedResult.method,
                quality: MeshVolumeResult.MeshQuality(
                    isWatertight: enhancedResult.quality.isWatertight,
                    hasNormals: enhancedResult.quality.hasNormals,
                    triangleDensity: enhancedResult.quality.triangleDensity,
                    qualityScore: enhancedResult.quality.qualityScore
                ),
                triangleCount: enhancedResult.triangleCount,
                isClosed: enhancedResult.isClosed
            )

            meshVolumeResult = meshResult
            meshQualityDescription = enhancedResult.quality.description

            // Use mesh volume if it's more accurate (enhanced version has higher confidence)
            if enhancedResult.confidence > 0.7 {
                volume_cm3 = enhancedResult.volume_cm3

                // Recalculate weight with new volume
                calculateWeight()
            }
        }
    }

    /// Export 3D model to file
    func export3DModel(format: MeshExportFormat = .obj, fileName: String? = nil) async throws -> MeshExportResult {
        // ‚úÖ FIX: Use stored camera (not arSession) to avoid ARFrame retention
        guard !meshAnchors.isEmpty, let camera = lastCamera else {
            throw ExportError.noMeshAnchorsAvailable
        }

        return try MeshExporter.exportMeshAnchors(
            meshAnchors,
            camera: camera,
            format: format,
            fileName: fileName
        )
    }

    private func detectTablePlane(from points: [simd_float3], normals: [simd_float3]) {
        // Find horizontal surfaces (table/floor)
        var horizontalPoints: [simd_float3] = []

        for i in 0..<min(points.count, normals.count) {
            let normal = normals[i]
            // Check if normal is pointing up (dot product with up vector)
            if abs(dot(normal, simd_float3(0, 1, 0))) > 0.9 {
                horizontalPoints.append(points[i])
            }
        }

        if !horizontalPoints.isEmpty {
            // Find most common Y value (histogram)
            let yValues = horizontalPoints.map { $0.y }
            detectedPlaneHeight = yValues.reduce(0, +) / Float(yValues.count)
        }
    }

    private func evaluateAccuracy(volumeResult: VolumeResult, points: [simd_float3], confidence: [Float]) {
        guard let cameraPosition = arSession?.currentFrame?.camera.transform.columns.3 else { return }

        let metrics = ScanQualityMetrics.from(
            points: points,
            confidence: confidence,
            cameraPosition: simd_float3(cameraPosition.x, cameraPosition.y, cameraPosition.z),
            isCalibrated: isCalibrated
        )

        let accuracyResult = accuracyEvaluator.evaluateAccuracy(
            metrics: metrics,
            materialCategory: selectedMaterial.category,
            calibrationFactor: calibrationManager.calibrationFactor
        )

        // Update UI
        self.confidence = Double(accuracyResult.confidenceLevel)
        self.qualityScore = Double(accuracyResult.qualityScore)
        self.recommendations = accuracyResult.recommendations

        // Calculate error margin
        calculateErrorMargin(
            volumeResult: volumeResult,
            qualityScore: accuracyResult.qualityScore,
            confidenceLevel: accuracyResult.confidenceLevel,
            pointCount: points.count
        )
    }

    /// Calculate measurement error margin based on scan quality factors
    private func calculateErrorMargin(
        volumeResult: VolumeResult,
        qualityScore: Float,
        confidenceLevel: Float,
        pointCount: Int
    ) {
        // Base error margin depends on volume calculation method
        var baseError: Double = 0.0

        switch volumeResult.method {
        case .boundingBox:
            baseError = 15.0  // ¬±15% for simple bounding box
        case .convexHull:
            baseError = 10.0  // ¬±10% for convex hull
        case .heightMap:
            baseError = 8.0   // ¬±8% for height map (good for powders)
        case .meshBased:
            baseError = 5.0   // ¬±5% for mesh-based (most accurate)
        }

        // Adjust based on calibration
        if isCalibrated {
            let calibrationAccuracy = Double(calibrationManager.calibrationAccuracy)
            if calibrationAccuracy > 90 {
                baseError *= 0.7  // Reduce by 30% for excellent calibration
            } else if calibrationAccuracy > 75 {
                baseError *= 0.85  // Reduce by 15% for good calibration
            }
        } else {
            baseError *= 1.3  // Increase by 30% without calibration
        }

        // Adjust based on scan quality
        if qualityScore > 0.9 {
            baseError *= 0.8  // Reduce by 20% for excellent quality
        } else if qualityScore < 0.5 {
            baseError *= 1.4  // Increase by 40% for poor quality
        }

        // Adjust based on confidence level
        if confidenceLevel > 0.8 {
            baseError *= 0.9  // Reduce by 10% for high confidence
        } else if confidenceLevel < 0.5 {
            baseError *= 1.2  // Increase by 20% for low confidence
        }

        // Adjust based on point count
        if pointCount > 5000 {
            baseError *= 0.95  // Reduce by 5% for high point density
        } else if pointCount < 1000 {
            baseError *= 1.15  // Increase by 15% for low point density
        }

        // Cap error margin between 3% and 25%
        let finalError = max(3.0, min(25.0, baseError))

        self.errorMarginPercent = finalError
        self.errorMarginDescription = formatErrorMargin(finalError)

        print("üìä Error Margin: ¬±\(String(format: "%.1f%%", finalError))")
    }

    /// Format error margin for display
    private func formatErrorMargin(_ errorPercent: Double) -> String {
        switch errorPercent {
        case 0..<5:
            return "Sehr pr√§zise (¬±\(String(format: "%.1f%%", errorPercent)))"
        case 5..<10:
            return "Pr√§zise (¬±\(String(format: "%.1f%%", errorPercent)))"
        case 10..<15:
            return "Gut (¬±\(String(format: "%.1f%%", errorPercent)))"
        case 15..<20:
            return "Akzeptabel (¬±\(String(format: "%.1f%%", errorPercent)))"
        default:
            return "Ungenau (¬±\(String(format: "%.1f%%", errorPercent)))"
        }
    }

    private func performSpatialAnalysis(points: [simd_float3], boundingBox: BoundingBox) {
        let heatMap = spatialAnalyzer.analyzeSpatialDensity(points: points, boundingBox: boundingBox)
        self.coverageScore = heatMap.overallCoverage

        if heatMap.needsMoreScanning, let cameraPos = arSession?.currentFrame?.camera.transform.columns.3 {
            let hints = spatialAnalyzer.getScanDirectionHints(
                heatMap: heatMap,
                currentCameraPosition: simd_float3(cameraPos.x, cameraPos.y, cameraPos.z)
            )
            recommendations.append(contentsOf: hints)
        }
    }

    // MARK: - Weight Calculation
    private func calculateWeight() {
        // Get density (consider packing for powders)
        var density = selectedMaterial.density

        // Adjust for packing if applicable
        if selectedMaterial.packingFactor != nil {
            // For powders, assume loose packing
            density = selectedMaterial.adjustedDensity(packed: false)
        }

        // Weight = Volume (cm¬≥) √ó Density (g/cm¬≥)
        weight_g = volume_cm3 * density

        // Apply calibration correction if available
        if isCalibrated, let factor = calibrationManager.calibrationFactor {
            weight_g *= Double(factor)
        }
    }

    // MARK: - Formatted Outputs
    var formattedVolume: String {
        // ‚úÖ CRASH FIX: Guard against NaN/Infinite values
        guard volume_cm3.isFinite && volume_cm3 >= 0 else {
            return "-- cm¬≥"
        }

        if volume_cm3 < 10 {
            return String(format: "%.2f cm¬≥", volume_cm3)
        } else if volume_cm3 < 1000 {
            return String(format: "%.1f cm¬≥", volume_cm3)
        } else {
            let liters = volume_cm3 / 1000.0
            return String(format: "%.2f L", liters)
        }
    }

    /// Formatted volume with error margin
    var formattedVolumeWithError: String {
        let volumeStr = formattedVolume
        if errorMarginPercent > 0 {
            return "\(volumeStr) (¬±\(String(format: "%.1f%%", errorMarginPercent)))"
        }
        return volumeStr
    }

    var formattedWeight: String {
        // ‚úÖ CRASH FIX: Guard against NaN/Infinite values
        guard weight_g.isFinite && weight_g >= 0 else {
            return "-- g"
        }

        if weight_g < 1 {
            return String(format: "%.2f g", weight_g)
        } else if weight_g < 1000 {
            return String(format: "%.1f g", weight_g)
        } else {
            let kg = weight_g / 1000.0
            return String(format: "%.2f kg", kg)
        }
    }

    var formattedDimensions: String {
        // ‚úÖ CRASH FIX: Guard against NaN/Infinite values
        guard dimensions.x.isFinite && dimensions.y.isFinite && dimensions.z.isFinite else {
            return "-- √ó -- √ó -- cm"
        }

        return String(format: "%.1f √ó %.1f √ó %.1f cm", dimensions.x, dimensions.y, dimensions.z)
    }

    var qualityRating: String {
        return accuracyEvaluator.getQualityRating(qualityScore: Float(qualityScore))
    }
}
